{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNBmCiwH3772cTjnZgc5uC/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 학습 관련 정보 저장하기\n","인공 신경망 학습은 그 크기에 따라 몇 초 혹은 며칠이 걸릴 수 있는 작업이다. 따라서 작업이 길어질 경우 관련 정보를 중간에 저장해야만 같은 작업을 반복하지 않을 수 있다. 또한 정전, 인터넷 장애 등과 같은 예상치 못한 일로 작업을 도중에 중단할 경우가 발생하기도 한다. 이 때 저장된 정보를 활용하여 다시 중단한 시점부터 학습을 재개할 수 있다."],"metadata":{"id":"iCf0Pouc0VqN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vS_bD84z00Xh","executionInfo":{"status":"ok","timestamp":1691375386249,"user_tz":-540,"elapsed":20104,"user":{"displayName":"이기환","userId":"15706483123137731910"}},"outputId":"8191bd0c-3166-4128-e2e0-ba3d8a6dd155"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["cd/content/gdrive/MyDrive/파이토치/딥러닝호형"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Ia3V35X059A","executionInfo":{"status":"ok","timestamp":1691375392638,"user_tz":-540,"elapsed":319,"user":{"displayName":"이기환","userId":"15706483123137731910"}},"outputId":"c5d3e1b5-7e2c-483a-8f22-e23872c578ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/파이토치/딥러닝호형\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn.functional as F\n","\n","from sklearn.metrics import mean_squared_error\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"viWbmLH71FRc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1) 데이터 불러오기"],"metadata":{"id":"tml0biyV1alR"}},{"cell_type":"code","source":["df = pd.read_csv('./data/reg.csv', index_col=[0])"],"metadata":{"id":"5KEWsiVe1gR_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2) 데이터 변수와 타겟값 나누기"],"metadata":{"id":"hQY7Kyp01sUq"}},{"cell_type":"code","source":["X = df.drop('Price', axis=1).to_numpy()\n","Y = df['Price'].to_numpy().reshape((-1, 1))"],"metadata":{"id":"SAgo0N5S1sop"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3) 텐서 데이터와 배치 만들기"],"metadata":{"id":"UA4ZAynD1suP"}},{"cell_type":"code","source":["class TensorData(Dataset):\n","\n","  def __init__(self, x_data, y_data):\n","    self.x_data = torch.FloatTensor(x_data)\n","    self.y_data = torch.FloatTensor(y_data)\n","    self.len = self.y_data.shape[0]\n","\n","  def __getitem__(self, index):\n","\n","    return self.x_data[index], self.y_data[index]\n","\n","  def __len__(self):\n","    return self.len"],"metadata":{"id":"5zSb5VYa1s0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, tset_size=0.5)\n","\n","trainsets = TensorData(X_train, Y_train)\n","trainloader = torch.utils.data.DataLoader(trainsets, batch_size=32, shuffle=True)\n","\n","testsets = TensorData(X_test, Y_test)\n","testloader = torch.utils.data.DataLoader(testsets, batch_size=32, shuffle=False)"],"metadata":{"id":"WAj3_n4F1s48"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4) 모델 구축\n","모델은 Regressor로 정의하며 입력층(노드13개), 2개의 은닉층(50개, 30개), 출력층(1개)으로 구성한다. 데이터의 변수는 13개이므로 입력층의 노드는 13개가 되고, 출력층은 집 값 단일 값을 추출하는 것이기에 1개가 된다. 은닉층에 대해서는 실험을 하면서 튜닝을 할 수 있다."],"metadata":{"id":"-YIFEEdo1s98"}},{"cell_type":"code","source":["class Regressor(nn.Module):\n","  def __init__(self):\n","    super.__init__() # 모델 연산 정의\n","    self.fc1 = nn.Linear(13, 50, bias=True) # 입력층(13)->은닉층1(50)으로 가는 연산\n","    self.fc2 = nn.Linear(50, 30, bias=True) # 입력층1(50)->은닉2(30)으로 가는 연산\n","    self.fc3 = nn.Linear(30, 1, bias=True) # 입력층2(30)->출력층(1)으로 가는 연산\n","    self.dropout = nn.Dropout(0.2) # 연산이 될 때마다 20%의 비율로 랜덤하게 노드를 없앤다.\n","\n","  def forward(self, x):\n","    x = F.relu(self.fc1(x))\n","    x = self.dropout(F.relu(self.fc2(x)))\n","    x = F.relu(self.fc3(x))\n","\n","    return x\n","\n","# 주의할 점은 dropout은 과적합 방지를 위한 노드 제거이므로, 출력층에서는 절대 사용X"],"metadata":{"id":"mr1GKTs91tCe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5) 모델, 손실함수, 최적화 방법 선언"],"metadata":{"id":"YqPu8nBB1tGw"}},{"cell_type":"code","source":["model = Regressor()\n","criterion = nn.MSELoss()\n","\n","# lr은 학습률\n","# weight_decay는 L2 정규화에서의 penalty 정도를 의미\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)"],"metadata":{"id":"imstb4m_1tLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pret = 0\n","\n","if pret == 1: # pretrain 모델이 있을 때는 pret를 1로 해서 아래를 실행하여 변수 선언(값 할당)\n","  checkpoint = torch.load('./model/4-4reg.pt')\n","  model.load_state_dict(checkpoint['model'])\n","  optimizer.load_state_dict(checkpoint['optimizer'])\n","  loss = checkpoint['loss']\n","  ep = checkpoint['ep']\n","  ls = loss_[-1]\n","  print(f'epoch={ep}, loss={ls}')\n","  ep = ep + 1\n","\n","else: # predtrain 모델이 없을 때\n","  ep = 0 # 에폭 0부터 시작\n","  ls = 1 # ls 1미만이면 모델 저장\n","  loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트"],"metadata":{"id":"c59fHQ4W1tPe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6) 학습 진행"],"metadata":{"id":"A7bZekPT1tc0"}},{"cell_type":"code","source":["n = len(trainloader)\n","\n","for epoch in range(ep, 2000):\n","\n","  running_loss = 0.0\n","\n","  for i, data in enumerate(trainloader, 0): # 무작위로 섞인 32개 데이터가 있는 배치가 하나씩 들어온다.\n","    inputs, values = data # data에는 X, Y가 들어있다.\n","\n","    optimize.zero_grad() # 최적화 초기화\n","\n","    outptus = model(inputs) # 모델에 입력값 대입 후 예측값 산출\n","    loss = criterion(outputs, values) # 손실 함수 계산\n","    loss.backward() # 손실 함수 기준으로 역전파 실행\n","    optimizer.step() # 역전파를 진행하고 가중치 업데이트\n","\n","    running_loss += loss.item() # epoch 마다 평균 loss를 계산하기 위해 배치 loss를 더한다.\n","\n","  l = running_loss/n\n","  loss_.append(l) # MSE(Mena Squared Error) 계산\n","  if l < ls: # 모델 저장\n","    torch.save({'epoch' : epoch,\n","                'loss' : loss_,\n","                'model' : model.state_dict(),\n","                'optimizer': optimizer.state_dict()\n","                },\n","               './models/4-4reg.pt') # dict를 통해 여러가지 정보를 저장할 수 있다!\n","\n","print('Finished Training')"],"metadata":{"id":"XMwLFx4Q1tkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(loss_)"],"metadata":{"id":"K2JrfI-Z5l61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(loss_)\n","plt.title('Training Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"metadata":{"id":"amcZfDV85moJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7) 모델 평가"],"metadata":{"id":"MnchvmuC7pXV"}},{"cell_type":"code","source":["def evaluate(dataloader):\n","\n","  predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서\n","  actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서\n","\n","  with torch.no_grad():\n","    model.eval() # 평가를 할 때에는 .eval() 반드시 사용해야 한다.\n","    for data in dataloader:\n","      inputs, values = data\n","\n","      predictions = torch.cat((predictions, outputs), 0) # cat을 통해 예측값을 누적\n","      actual = torch.cat((actual, values), 0) # cat을 통해 실제값을 누적\n","  rmse = np.sqrt(mean_squared_error(predictions, actual)) # sklearn을 이용한 rmse계산\n","\n","  return rmse\n","\n","# 평가 시 .eval()을 사용해야 하는 이유\n","# 평가 시에는 온전한 모델로 평가를 해야 하는데 .eval()이 아닌 .train()인 경우 드롭아웃이 활성화되어 있다.\n","# 따라서 드롭아웃이나 배치 정규화 등과같이 학습 시에만 사용하는 기술들을 평가 시에는 비활성화해야 한다."],"metadata":{"id":"e73-vZhz7piL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cheackpoint = torch.load('./models/4-4reg.pt')\n","model.load_state_dict(checkpoint['model'])"],"metadata":{"id":"rr3QbpGf7psd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_rmse = evaluation(trainloader) # 학습 데이터의 rmse\n","test_rmse = evaluation(testloader) # test data 의 rmse\n","\n","print(f'Train RMSE : {train_rmse}')\n","print(f'Test RMSE : {test_rmse}')\n","\n","# 예시를 위한 단순한 비교일 뿐"],"metadata":{"id":"UwPMaPWy7p2I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BQuX5pn47qB_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ax9A9u305m01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k3Jpf1lx5nC3"},"execution_count":null,"outputs":[]}]}